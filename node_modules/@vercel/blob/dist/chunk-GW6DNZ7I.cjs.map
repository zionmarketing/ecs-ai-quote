{"version":3,"sources":["/home/runner/work/storage/storage/packages/blob/dist/chunk-GW6DNZ7I.cjs","../src/helpers.ts","../src/api.ts","../src/debug.ts","../src/put-helpers.ts","../src/multipart/complete.ts","../src/multipart/create.ts","../src/multipart/upload.ts","../src/multipart/helpers.ts","../src/multipart/uncontrolled.ts","../src/put.ts","../src/multipart/create-uploader.ts","../src/create-folder.ts"],"names":["error"],"mappings":"AAAA;ACsCO,SAAS,wBAAA,CAAyB,OAAA,EAAsC;AAC7E,EAAA,GAAA,CAAI,QAAA,GAAA,KAAA,EAAA,KAAA,EAAA,EAAA,OAAA,CAAS,KAAA,EAAO;AAClB,IAAA,OAAO,OAAA,CAAQ,KAAA;AAAA,EACjB;AAEA,EAAA,GAAA,CAAI,OAAA,CAAQ,GAAA,CAAI,qBAAA,EAAuB;AACrC,IAAA,OAAO,OAAA,CAAQ,GAAA,CAAI,qBAAA;AAAA,EACrB;AAEA,EAAA,MAAM,IAAI,SAAA;AAAA,IACR;AAAA,EACF,CAAA;AACF;AAEO,IAAM,UAAA,EAAN,MAAA,QAAwB,MAAM;AAAA,EACnC,WAAA,CAAY,OAAA,EAAiB;AAC3B,IAAA,KAAA,CAAM,CAAA,aAAA,EAAgB,OAAO,CAAA,CAAA;AAC/B,EAAA;AACF;AAEwD;AAC3B,EAAA;AAEN,EAAA;AAED,EAAA;AACtB;AAIuD;AAChC,EAAA;AACZ,IAAA;AACT,EAAA;AAGyB,EAAA;AAGrB,EAAA;AAKN;ADrDkC;AACA;AE7BZ;AACJ;AF+BgB;AACA;AGlCd;AAApB;AAGI;AAEY,EAAA;AAGI,IAAA;AAClB,EAAA;AACc;AAEhB;AAGiE;AAC5C,EAAA;AAEa,IAAA;AAChC,EAAA;AACF;AH4BkC;AACA;AEtCK;AAEhC;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AACwB,EAAA;AACrB,IAAA;AACR,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAEO;AAGyB,EAAA;AAC5B,IAAA;AACE,MAAA;AAGF,IAAA;AAEkB,IAAA;AACpB,EAAA;AACF;AAEO;AACS,EAAA;AACN,IAAA;AACR,EAAA;AACF;AAqByB;AAEQ;AACT,EAAA;AAClB,EAAA;AAIY,IAAA;AAER,EAAA;AAER,EAAA;AAEU,EAAA;AACZ;AAE0C;AAC1B,EAAA;AACV,EAAA;AAIY,IAAA;AAER,EAAA;AAER,EAAA;AACqB,EAAA;AACvB;AAE8B;AACxB,EAAA;AAC0B,IAAA;AAED,IAAA;AACrB,EAAA;AACC,IAAA;AACT,EAAA;AACF;AAES;AAGqB,EAAA;AAEjB,EAAA;AACa,IAAA;AACxB,EAAA;AACF;AAIE;AAnJF,EAAA;AAqJM,EAAA;AACA,EAAA;AAEA,EAAA;AAC2B,IAAA;AAEjB,IAAA;AACG,IAAA;AACT,EAAA;AACC,IAAA;AACT,EAAA;AAKI,EAAA;AACK,IAAA;AACT,EAAA;AAEI,EAAA;AACU,EAAA;AACP,IAAA;AACS,MAAA;AACZ,MAAA;AACG,IAAA;AACyB,MAAA;AAC5B,MAAA;AACG,IAAA;AAES,MAAA;AACZ,MAAA;AACG,IAAA;AACS,MAAA;AACZ,MAAA;AACG,IAAA;AACS,MAAA;AACZ,MAAA;AACG,IAAA;AACmB,MAAA;AACtB,MAAA;AACG,IAAA;AACS,MAAA;AACZ,MAAA;AACG,IAAA;AACK,MAAA;AACR,MAAA;AACG,IAAA;AACA,IAAA;AACL,IAAA;AACc,MAAA;AACZ,MAAA;AACJ,EAAA;AAEqB,EAAA;AACvB;AAGE;AAImB,EAAA;AACL,EAAA;AACO,EAAA;AAEQ,EAAA;AACG,EAAA;AACf,EAAA;AAES,EAAA;AACR,IAAA;AACV,MAAA;AAGA,MAAA;AACgB,QAAA;AACb,UAAA;AACM,UAAA;AACP,YAAA;AACA,YAAA;AACiB,YAAA;AACF,YAAA;AACZ,YAAA;AACK,YAAA;AACV,UAAA;AACD,QAAA;AACa,MAAA;AAEO,QAAA;AACV,UAAA;AACT,UAAA;AACF,QAAA;AAGMA,QAAAA;AACR,MAAA;AAEY,MAAA;AACH,QAAA;AACT,MAAA;AAEwB,MAAA;AAIb,MAAA;AAIH,QAAA;AACR,MAAA;AAGU,MAAA;AACZ,IAAA;AACA,IAAA;AACsB,MAAA;AACA,MAAA;AACZ,QAAA;AACoB,QAAA;AAC5B,MAAA;AACF,IAAA;AACF,EAAA;AAEkB,EAAA;AACW,IAAA;AAC7B,EAAA;AAE+B,EAAA;AACjC;AAES;AAGuC,EAAA;AAE1C,EAAA;AACE,IAAA;AACW,MAAA;AAEC,MAAA;AAEd,IAAA;AAEa,MAAA;AAEC,MAAA;AAChB,IAAA;AACM,EAAA;AAER,EAAA;AAEO,EAAA;AACT;AF3DkC;AACA;AI7OA;AACZ,EAAA;AACH,EAAA;AACJ,EAAA;AACf;AA+BE;AAGyC,EAAA;AAEb,EAAA;AACC,IAAA;AAC7B,EAAA;AAG0B,EAAA;AAGG,IAAA;AAG7B,EAAA;AAG0B,EAAA;AAGG,IAAA;AAE7B,EAAA;AAEO,EAAA;AACT;AAIE;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AAMoB;AACL,EAAA;AACO,IAAA;AACtB,EAAA;AAEsB,EAAA;AACV,IAAA;AACR,MAAA;AACF,IAAA;AACF,EAAA;AAEc,EAAA;AACQ,IAAA;AACtB,EAAA;AAGuB,EAAA;AACD,IAAA;AACtB,EAAA;AAEiB,EAAA;AACI,IAAA;AACrB,EAAA;AAEc,EAAA;AACU,IAAA;AACxB,EAAA;AAEO,EAAA;AACT;AJmLkC;AACA;AKhRlB;AAGiC,EAAA;AACvB,IAAA;AACpB,MAAA;AACS,MAAA;AACT,MAAA;AACA,MAAA;AACD,IAAA;AAEe,IAAA;AAET,IAAA;AACa,MAAA;AACL,MAAA;AACb,MAAA;AACA,MAAA;AACA,MAAA;AACA,MAAA;AACD,IAAA;AACH,EAAA;AACF;AAEsB;AACpB,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AAQyB;AACrB,EAAA;AACqB,IAAA;AACL,MAAA;AAChB,MAAA;AACU,QAAA;AACC,QAAA;AACJ,UAAA;AACa,UAAA;AACA,UAAA;AACG,UAAA;AAAA;AAAA;AAGI,UAAA;AACzB,QAAA;AAC0B,QAAA;AACV,QAAA;AAClB,MAAA;AACA,MAAA;AACF,IAAA;AAEuB,IAAA;AAEhB,IAAA;AACgB,EAAA;AAEJ,IAAA;AAGP,MAAA;AACL,IAAA;AACC,MAAA;AACR,IAAA;AACF,EAAA;AACF;ALiQkC;AACA;AMxVlB;AAGkB,EAAA;AACR,IAAA;AACpB,MAAA;AACS,MAAA;AACT,MAAA;AACA,MAAA;AACD,IAAA;AAEe,IAAA;AAEV,IAAA;AACJ,MAAA;AACA,MAAA;AACA,MAAA;AACF,IAAA;AAEO,IAAA;AACA,MAAA;AACK,MAAA;AACZ,IAAA;AACF,EAAA;AACF;AAOsB;AAKC,EAAA;AAEjB,EAAA;AACqB,IAAA;AACL,MAAA;AAChB,MAAA;AACU,QAAA;AACC,QAAA;AACJ,UAAA;AACa,UAAA;AAClB,QAAA;AACgB,QAAA;AAClB,MAAA;AACA,MAAA;AACF,IAAA;AAE6B,IAAA;AAEtB,IAAA;AACgB,EAAA;AAEJ,IAAA;AAGP,MAAA;AACL,IAAA;AACC,MAAA;AACR,IAAA;AACF,EAAA;AACF;ANqUkC;AACA;AO7YhB;AA0Bd;AAIA,EAAA;AAEsB,IAAA;AACpB,MAAA;AACS,MAAA;AACT,MAAA;AACA,MAAA;AACD,IAAA;AAEe,IAAA;AAES,IAAA;AACb,MAAA;AACR,QAAA;AACF,MAAA;AACF,IAAA;AAEqB,IAAA;AACD,MAAA;AACL,MAAA;AACb,MAAA;AACoB,MAAA;AACpB,MAAA;AACA,MAAA;AACD,IAAA;AAEM,IAAA;AACQ,MAAA;AACO,MAAA;AACtB,IAAA;AACF,EAAA;AACF;AAEiC;AAC/B,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AAC8B,EAAA;AAC9B,EAAA;AASiC;AA/EnC,EAAA;AAgF0B,EAAA;AACN,IAAA;AAChB,IAAA;AACU,MAAA;AACA,MAAA;AACC,MAAA;AACJ,QAAA;AACa,QAAA;AACU,QAAA;AACP,QAAA;AACO,QAAA;AAC5B,MAAA;AAAA;AAEW,MAAA;AAAA;AAAA;AAAA;AAIH,MAAA;AACV,IAAA;AACA,IAAA;AACF,EAAA;AAE6B,EAAA;AACG,IAAA;AAChC,EAAA;AAEY,EAAA;AAEE,IAAA;AACP,EAAA;AAEG,IAAA;AACV,EAAA;AAEuB,EAAA;AAEvB,EAAA;AAEO,EAAA;AACT;AAIoC;AAGD;AAEV;AAYM;AAC7B,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AACA,EAAA;AAQkB;AACQ,EAAA;AACM,EAAA;AAEH,EAAA;AACc,IAAA;AACT,IAAA;AACV,IAAA;AACF,IAAA;AACN,IAAA;AACU,IAAA;AAET,IAAA;AACY,IAAA;AACT,IAAA;AACF,IAAA;AAImB,IAAA;AACR,IAAA;AAER,IAAA;AAEkB,IAAA;AACnC,MAAA;AACE,QAAA;AACA,QAAA;AACA,QAAA;AACA,QAAA;AACS,QAAA;AACT,QAAA;AACe,QAAA;AACjB,MAAA;AAEU,MAAA;AAEH,MAAA;AACD,QAAA;AAEsB,UAAA;AAEd,UAAA;AACM,YAAA;AACR,YAAA;AAEW,YAAA;AACI,cAAA;AACL,gBAAA;AACG,gBAAA;AACP,kBAAA;AACP,gBAAA;AACF,cAAA;AAES,cAAA;AACZ,YAAA;AACU,YAAA;AACV,YAAA;AACF,UAAA;AAEwB,UAAA;AAIN,UAAA;AACG,UAAA;AACb,YAAA;AACY,YAAA;AACF,cAAA;AACR,cAAA;AACR,YAAA;AAEoB,YAAA;AAEF,YAAA;AAClB,YAAA;AACc,YAAA;AAEV,YAAA;AACiB,cAAA;AACL,gBAAA;AACG,gBAAA;AACP,kBAAA;AACP,gBAAA;AACF,cAAA;AAEe,cAAA;AAChB,cAAA;AACU,cAAA;AACZ,YAAA;AACF,UAAA;AACc,QAAA;AACF,UAAA;AACd,QAAA;AACF,MAAA;AAEA,MAAA;AACE,QAAA;AACA,QAAA;AACA,QAAA;AACA,QAAA;AACS,QAAA;AACT,QAAA;AACe,QAAA;AACjB,MAAA;AAEU,MAAA;AACZ,IAAA;AAE6D,IAAA;AAC3D,MAAA;AAEA,MAAA;AACE,QAAA;AACA,QAAA;AACK,QAAA;AACL,QAAA;AACU,QAAA;AACV,QAAA;AACA,QAAA;AACA,QAAA;AACS,QAAA;AACT,QAAA;AACe,QAAA;AACjB,MAAA;AAEI,MAAA;AACoB,QAAA;AACpB,UAAA;AACA,UAAA;AACA,UAAA;AACA,UAAA;AACA,UAAA;AACA,UAAA;AACA,UAAA;AACD,QAAA;AAED,QAAA;AACE,UAAA;AACA,UAAA;AACK,UAAA;AACL,UAAA;AACA,UAAA;AACA,UAAA;AACS,UAAA;AACT,UAAA;AACe,UAAA;AACjB,QAAA;AAEc,QAAA;AACZ,UAAA;AACF,QAAA;AAEoB,QAAA;AACD,UAAA;AACG,UAAA;AACrB,QAAA;AAEuB,QAAA;AACxB,QAAA;AACuB,QAAA;AAEL,QAAA;AACN,UAAA;AACZ,QAAA;AAEiB,QAAA;AACO,UAAA;AACD,YAAA;AACG,YAAA;AACxB,UAAA;AACA,UAAA;AACF,QAAA;AAEc,QAAA;AACO,UAAA;AACrB,QAAA;AACc,MAAA;AAEF,QAAA;AACd,MAAA;AACF,IAAA;AAE2B,IAAA;AACX,MAAA;AACZ,QAAA;AACF,MAAA;AAEA,MAAA;AACE,QAAA;AACA,QAAA;AACA,QAAA;AACA,QAAA;AACc,QAAA;AAChB,MAAA;AAEuB,MAAA;AACF,QAAA;AACH,QAAA;AACU,UAAA;AAC1B,QAAA;AACF,MAAA;AACF,IAAA;AAEsC,IAAA;AAEtB,MAAA;AACZ,QAAA;AACF,MAAA;AACW,MAAA;AACa,MAAA;AACL,MAAA;AAEA,MAAA;AAIN,QAAA;AACN,MAAA;AACgB,QAAA;AACvB,MAAA;AACF,IAAA;AACD,EAAA;AACH;AP4RkC;AACA;AQrpBT;AAGJ;AAayD;AAEvD,EAAA;AACZ,IAAA;AACT,EAAA;AAK2B,EAAA;AACL,IAAA;AACtB,EAAA;AAEgC,EAAA;AACH,IAAA;AAC7B,EAAA;AAEI,EAAA;AAEiB,EAAA;AACL,IAAA;AACL,EAAA;AACW,IAAA;AACf,EAAA;AACS,IAAA;AAChB,EAAA;AAGuC,EAAA;AACnB,IAAA;AACG,MAAA;AACF,MAAA;AACnB,IAAA;AACD,EAAA;AACH;AAGgC;AAEX,EAAA;AAKe,EAAA;AAEpC;AAEmD;AACrB,EAAA;AACT,EAAA;AACrB;AAEgC;AACT,EAAA;AACvB;ARqnBkC;AACA;ASrrBZ;AAMY,EAAA;AAEA,EAAA;AAG1B,EAAA;AACJ,IAAA;AACA,IAAA;AACA,IAAA;AACF,EAAA;AAGoB,EAAA;AACR,IAAA;AACL,IAAA;AACL,IAAA;AACA,IAAA;AACA,IAAA;AACA,IAAA;AACD,EAAA;AAGkB,EAAA;AACP,IAAA;AACL,IAAA;AACL,IAAA;AACA,IAAA;AACA,IAAA;AACA,IAAA;AACD,EAAA;AAEM,EAAA;AACT;AT0qBkC;AACA;AUrsBkC;AAClE,EAAA;AACA,EAAA;AACA,EAAA;AACmC;AAEjC,EAAA;AAIW,IAAA;AACW,MAAA;AACtB,IAAA;AAEyB,IAAA;AACb,MAAA;AACR,QAAA;AACF,MAAA;AACF,IAAA;AAEsB,IAAA;AACpB,MAAA;AACS,MAAA;AACT,MAAA;AACA,MAAA;AACD,IAAA;AAEe,IAAA;AAEU,IAAA;AACjB,MAAA;AACT,IAAA;AAEuB,IAAA;AACT,MAAA;AACZ,MAAA;AACU,QAAA;AACR,QAAA;AACA,QAAA;AAAA;AAAA;AAAA;AAIQ,QAAA;AACQ,QAAA;AAClB,MAAA;AACA,MAAA;AACF,IAAA;AAEO,IAAA;AACS,MAAA;AACQ,MAAA;AACH,MAAA;AACG,MAAA;AACF,MAAA;AACtB,IAAA;AACF,EAAA;AACF;AV6rBkC;AACA;AW/vBlB;AAGkB,EAAA;AACR,IAAA;AACpB,MAAA;AACS,MAAA;AACT,MAAA;AACA,MAAA;AACD,IAAA;AAEe,IAAA;AAEV,IAAA;AACJ,MAAA;AACA,MAAA;AACA,MAAA;AACF,IAAA;AAEO,IAAA;AACA,MAAA;AACK,MAAA;AAEO,MAAA;AACU,QAAA;AACb,UAAA;AACR,YAAA;AACF,UAAA;AACF,QAAA;AAEqB,QAAA;AACT,UAAA;AACL,UAAA;AACL,UAAA;AACoB,UAAA;AACpB,UAAA;AACA,UAAA;AACD,QAAA;AAEM,QAAA;AACQ,UAAA;AACb,UAAA;AACF,QAAA;AACF,MAAA;AAE8B,MAAA;AACrB,QAAA;AACK,UAAA;AACL,UAAA;AACL,UAAA;AACA,UAAA;AACA,UAAA;AACA,UAAA;AACD,QAAA;AACH,MAAA;AACF,IAAA;AACF,EAAA;AACF;AXwvBkC;AACA;AY7yBhC;AAG+B,EAAA;AAEU,EAAA;AAEd,EAAA;AAEJ,EAAA;AACb,IAAA;AACR,IAAA;AACU,MAAA;AACR,MAAA;AACgB,MAAA;AAClB,IAAA;AACA,IAAA;AACF,EAAA;AAEO,EAAA;AACS,IAAA;AACK,IAAA;AACrB,EAAA;AACF;AZyyBkC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","file":"/home/runner/work/storage/storage/packages/blob/dist/chunk-GW6DNZ7I.cjs","sourcesContent":[null,"// common util interface for blob raw commands, not meant to be used directly\n// this is why it's not exported from index/client\n\nexport interface BlobCommandOptions {\n  /**\n   * Define your blob API token.\n   * @defaultvalue process.env.BLOB_READ_WRITE_TOKEN\n   */\n  token?: string;\n  /**\n   * `AbortSignal` to cancel the running request. See https://developer.mozilla.org/en-US/docs/Web/API/AbortSignal\n   */\n  abortSignal?: AbortSignal;\n}\n\n// shared interface for put, copy and multipartUpload\nexport interface CommonCreateBlobOptions extends BlobCommandOptions {\n  /**\n   * Whether the blob should be publicly accessible.\n   */\n  access: 'public';\n  /**\n   * Adds a random suffix to the filename.\n   * @defaultvalue true\n   */\n  addRandomSuffix?: boolean;\n  /**\n   * Defines the content type of the blob. By default, this value is inferred from the pathname. Sent as the 'content-type' header when downloading a blob.\n   */\n  contentType?: string;\n  /**\n   * Number in seconds to configure the edge and browser cache. The maximum values are 5 minutes for the edge cache and unlimited for the browser cache.\n   * Detailed documentation can be found here: https://vercel.com/docs/storage/vercel-blob#caching\n   * @defaultvalue 365 * 24 * 60 * 60 (1 Year)\n   */\n  cacheControlMaxAge?: number;\n}\n\nexport function getTokenFromOptionsOrEnv(options?: BlobCommandOptions): string {\n  if (options?.token) {\n    return options.token;\n  }\n\n  if (process.env.BLOB_READ_WRITE_TOKEN) {\n    return process.env.BLOB_READ_WRITE_TOKEN;\n  }\n\n  throw new BlobError(\n    'No token found. Either configure the `BLOB_READ_WRITE_TOKEN` environment variable, or pass a `token` option to your calls.',\n  );\n}\n\nexport class BlobError extends Error {\n  constructor(message: string) {\n    super(`Vercel Blob: ${message}`);\n  }\n}\n\nexport function getDownloadUrl(blobUrl: string): string {\n  const url = new URL(blobUrl);\n\n  url.searchParams.set('download', '1');\n\n  return url.toString();\n}\n\n// Extracted from https://github.com/sindresorhus/is-plain-obj/blob/main/index.js\n// It's just nearly impossible to use ESM modules with our current setup\nexport function isPlainObject(value: unknown): boolean {\n  if (typeof value !== 'object' || value === null) {\n    return false;\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unsafe-assignment -- ok\n  const prototype = Object.getPrototypeOf(value);\n  return (\n    (prototype === null ||\n      prototype === Object.prototype ||\n      Object.getPrototypeOf(prototype) === null) &&\n    !(Symbol.toStringTag in value) &&\n    !(Symbol.iterator in value)\n  );\n}\n","import type { RequestInit, Response } from 'undici';\nimport { fetch } from 'undici';\nimport retry from 'async-retry';\nimport { debug } from './debug';\nimport type { BlobCommandOptions } from './helpers';\nimport { BlobError, getTokenFromOptionsOrEnv } from './helpers';\n\n// maximum pathname length is:\n// 1024 (provider limit) - 26 chars (vercel  internal suffixes) - 31 chars (blob `-randomId` suffix) = 967\n// we round it to 950 to make it more human friendly, and we apply the limit whatever the value of\n// addRandomSuffix is, to make it consistent\nexport const MAXIMUM_PATHNAME_LENGTH = 950;\n\nexport class BlobAccessError extends BlobError {\n  constructor() {\n    super('Access denied, please provide a valid token for this resource.');\n  }\n}\n\nexport class BlobContentTypeNotAllowed extends BlobError {\n  constructor(message: string) {\n    super(`Content type mismatch, ${message}`);\n  }\n}\n\nexport class BlobStoreNotFoundError extends BlobError {\n  constructor() {\n    super('This store does not exist.');\n  }\n}\n\nexport class BlobStoreSuspendedError extends BlobError {\n  constructor() {\n    super('This store has been suspended.');\n  }\n}\n\nexport class BlobUnknownError extends BlobError {\n  constructor() {\n    super('Unknown error, please visit https://vercel.com/help.');\n  }\n}\n\nexport class BlobNotFoundError extends BlobError {\n  constructor() {\n    super('The requested blob does not exist');\n  }\n}\n\nexport class BlobServiceNotAvailable extends BlobError {\n  constructor() {\n    super('The blob service is currently not available. Please try again.');\n  }\n}\n\nexport class BlobServiceRateLimited extends BlobError {\n  public readonly retryAfter: number;\n\n  constructor(seconds?: number) {\n    super(\n      `Too many requests please lower the number of concurrent requests ${\n        seconds ? ` - try again in ${seconds} seconds` : ''\n      }.`,\n    );\n\n    this.retryAfter = seconds ?? 0;\n  }\n}\n\nexport class BlobRequestAbortedError extends BlobError {\n  constructor() {\n    super('The request was aborted.');\n  }\n}\n\ntype BlobApiErrorCodes =\n  | 'store_suspended'\n  | 'forbidden'\n  | 'not_found'\n  | 'unknown_error'\n  | 'bad_request'\n  | 'store_not_found'\n  | 'not_allowed'\n  | 'service_unavailable'\n  | 'rate_limited'\n  | 'content_type_not_allowed';\n\nexport interface BlobApiError {\n  error?: { code?: BlobApiErrorCodes; message?: string };\n}\n\n// This version is used to ensure that the client and server are compatible\n// The server (Vercel Blob API) uses this information to change its behavior like the\n// response format\nconst BLOB_API_VERSION = 7;\n\nfunction getApiVersion(): string {\n  let versionOverride = null;\n  try {\n    // wrapping this code in a try/catch as this function is used in the browser and Vite doesn't define the process.env.\n    // As this varaible is NOT used in production, it will always default to the BLOB_API_VERSION\n    versionOverride =\n      process.env.VERCEL_BLOB_API_VERSION_OVERRIDE ||\n      process.env.NEXT_PUBLIC_VERCEL_BLOB_API_VERSION_OVERRIDE;\n  } catch {\n    // noop\n  }\n\n  return `${versionOverride ?? BLOB_API_VERSION}`;\n}\n\nfunction getApiUrl(pathname = ''): string {\n  let baseUrl = null;\n  try {\n    // wrapping this code in a try/catch as this function is used in the browser and Vite doesn't define the process.env.\n    // As this varaible is NOT used in production, it will always default to production endpoint\n    baseUrl =\n      process.env.VERCEL_BLOB_API_URL ||\n      process.env.NEXT_PUBLIC_VERCEL_BLOB_API_URL;\n  } catch {\n    // noop\n  }\n  return `${baseUrl || 'https://blob.vercel-storage.com'}${pathname}`;\n}\n\nfunction getRetries(): number {\n  try {\n    const retries = process.env.VERCEL_BLOB_RETRIES || '10';\n\n    return parseInt(retries, 10);\n  } catch {\n    return 10;\n  }\n}\n\nfunction createBlobServiceRateLimited(\n  response: Response,\n): BlobServiceRateLimited {\n  const retryAfter = response.headers.get('retry-after');\n\n  return new BlobServiceRateLimited(\n    retryAfter ? parseInt(retryAfter, 10) : undefined,\n  );\n}\n\n// reads the body of a error response\nasync function getBlobError(\n  response: Response,\n): Promise<{ code: string; error: BlobError }> {\n  let code: BlobApiErrorCodes;\n  let message: string | undefined;\n\n  try {\n    const data = (await response.json()) as BlobApiError;\n\n    code = data.error?.code ?? 'unknown_error';\n    message = data.error?.message;\n  } catch {\n    code = 'unknown_error';\n  }\n\n  // Now that we have multiple API clients out in the wild handling errors, we can't just send a different\n  // error code for this type of error. We need to add a new field in the API response to handle this correctly,\n  // but for now, we can just check the message.\n  if (message?.includes('contentType') && message.includes('is not allowed')) {\n    code = 'content_type_not_allowed';\n  }\n\n  let error: BlobError;\n  switch (code) {\n    case 'store_suspended':\n      error = new BlobStoreSuspendedError();\n      break;\n    case 'forbidden':\n      error = new BlobAccessError();\n      break;\n    case 'content_type_not_allowed':\n      // eslint-disable-next-line @typescript-eslint/no-non-null-assertion -- TS, be smarter\n      error = new BlobContentTypeNotAllowed(message!);\n      break;\n    case 'not_found':\n      error = new BlobNotFoundError();\n      break;\n    case 'store_not_found':\n      error = new BlobStoreNotFoundError();\n      break;\n    case 'bad_request':\n      error = new BlobError(message ?? 'Bad request');\n      break;\n    case 'service_unavailable':\n      error = new BlobServiceNotAvailable();\n      break;\n    case 'rate_limited':\n      error = createBlobServiceRateLimited(response);\n      break;\n    case 'unknown_error':\n    case 'not_allowed':\n    default:\n      error = new BlobUnknownError();\n      break;\n  }\n\n  return { code, error };\n}\n\nexport async function requestApi<TResponse>(\n  pathname: string,\n  init: RequestInit,\n  commandOptions: BlobCommandOptions | undefined,\n): Promise<TResponse> {\n  const apiVersion = getApiVersion();\n  const token = getTokenFromOptionsOrEnv(commandOptions);\n  const extraHeaders = getProxyThroughAlternativeApiHeaderFromEnv();\n\n  const [, , , storeId = ''] = token.split('_');\n  const requestId = `${storeId}:${Date.now()}:${Math.random().toString(16).slice(2)}`;\n  let retryCount = 0;\n\n  const apiResponse = await retry(\n    async (bail) => {\n      let res: Response;\n\n      // try/catch here to treat certain errors as not-retryable\n      try {\n        res = await fetch(getApiUrl(pathname), {\n          ...init,\n          headers: {\n            'x-api-blob-request-id': requestId,\n            'x-api-blob-request-attempt': String(retryCount),\n            'x-api-version': apiVersion,\n            authorization: `Bearer ${token}`,\n            ...extraHeaders,\n            ...init.headers,\n          },\n        });\n      } catch (error) {\n        // if the request was aborted, don't retry\n        if (error instanceof DOMException && error.name === 'AbortError') {\n          bail(new BlobRequestAbortedError());\n          return;\n        }\n\n        // retry for any other erros thrown by fetch\n        throw error;\n      }\n\n      if (res.ok) {\n        return res;\n      }\n\n      const { code, error } = await getBlobError(res);\n\n      // only retry for certain errors\n      if (\n        code === 'unknown_error' ||\n        code === 'service_unavailable' ||\n        code === 'internal_server_error'\n      ) {\n        throw error;\n      }\n\n      // don't retry for e.g. suspended stores\n      bail(error);\n    },\n    {\n      retries: getRetries(),\n      onRetry: (error) => {\n        debug(`retrying API request to ${pathname}`, error.message);\n        retryCount = retryCount + 1;\n      },\n    },\n  );\n\n  if (!apiResponse) {\n    throw new BlobUnknownError();\n  }\n\n  return (await apiResponse.json()) as TResponse;\n}\n\nfunction getProxyThroughAlternativeApiHeaderFromEnv(): {\n  'x-proxy-through-alternative-api'?: string;\n} {\n  const extraHeaders: Record<string, string> = {};\n\n  try {\n    if ('VERCEL_BLOB_PROXY_THROUGH_ALTERNATIVE_API' in process.env) {\n      extraHeaders['x-proxy-through-alternative-api'] =\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion -- we know it's here from the if\n        process.env.VERCEL_BLOB_PROXY_THROUGH_ALTERNATIVE_API!;\n    } else if (\n      'NEXT_PUBLIC_VERCEL_BLOB_PROXY_THROUGH_ALTERNATIVE_API' in process.env\n    ) {\n      extraHeaders['x-proxy-through-alternative-api'] =\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion -- we know it's here from the if\n        process.env.NEXT_PUBLIC_VERCEL_BLOB_PROXY_THROUGH_ALTERNATIVE_API!;\n    }\n  } catch {\n    // noop\n  }\n\n  return extraHeaders;\n}\n","let debugIsActive = false;\n\n// wrapping this code in a try/catch in case some env doesn't support process.env (vite by default)\ntry {\n  if (\n    process.env.DEBUG?.includes('blob') ||\n    process.env.NEXT_PUBLIC_DEBUG?.includes('blob')\n  ) {\n    debugIsActive = true;\n  }\n} catch (error) {\n  // noop\n}\n\n// Set process.env.DEBUG = 'blob' to enable debug logging\nexport function debug(message: string, ...args: unknown[]): void {\n  if (debugIsActive) {\n    // eslint-disable-next-line no-console -- Ok for debugging\n    console.debug(`vercel-blob: ${message}`, ...args);\n  }\n}\n","// eslint-disable-next-line unicorn/prefer-node-protocol -- node:stream does not resolve correctly in browser and edge\nimport type { Readable } from 'stream';\nimport type { ClientCommonCreateBlobOptions } from './client';\nimport type { CommonCreateBlobOptions } from './helpers';\nimport { BlobError } from './helpers';\nimport { MAXIMUM_PATHNAME_LENGTH } from './api';\n\nexport const putOptionHeaderMap = {\n  cacheControlMaxAge: 'x-cache-control-max-age',\n  addRandomSuffix: 'x-add-random-suffix',\n  contentType: 'x-content-type',\n};\n\nexport interface PutBlobResult {\n  url: string;\n  downloadUrl: string;\n  pathname: string;\n  contentType?: string;\n  contentDisposition: string;\n}\n\nexport type PutBlobApiResponse = PutBlobResult;\n\nexport type PutBody =\n  | string\n  | Readable // Node.js streams\n  | Buffer // Node.js buffers\n  | Blob\n  | ArrayBuffer\n  | ReadableStream // Streams API (= Web streams in Node.js)\n  | File;\n\nexport type CommonPutCommandOptions = CommonCreateBlobOptions &\n  ClientCommonCreateBlobOptions;\n\nexport interface CreatePutMethodOptions<TOptions> {\n  allowedOptions: (keyof typeof putOptionHeaderMap)[];\n  getToken?: (pathname: string, options: TOptions) => Promise<string>;\n  extraChecks?: (options: TOptions) => void;\n}\n\nexport function createPutHeaders<TOptions extends CommonPutCommandOptions>(\n  allowedOptions: CreatePutMethodOptions<TOptions>['allowedOptions'],\n  options: TOptions,\n): Record<string, string> {\n  const headers: Record<string, string> = {};\n\n  if (allowedOptions.includes('contentType') && options.contentType) {\n    headers[putOptionHeaderMap.contentType] = options.contentType;\n  }\n\n  if (\n    allowedOptions.includes('addRandomSuffix') &&\n    options.addRandomSuffix !== undefined\n  ) {\n    headers[putOptionHeaderMap.addRandomSuffix] = options.addRandomSuffix\n      ? '1'\n      : '0';\n  }\n\n  if (\n    allowedOptions.includes('cacheControlMaxAge') &&\n    options.cacheControlMaxAge !== undefined\n  ) {\n    headers[putOptionHeaderMap.cacheControlMaxAge] =\n      options.cacheControlMaxAge.toString();\n  }\n\n  return headers;\n}\n\nexport async function createPutOptions<\n  TOptions extends CommonPutCommandOptions,\n>({\n  pathname,\n  options,\n  extraChecks,\n  getToken,\n}: {\n  pathname: string;\n  options?: TOptions;\n  extraChecks?: CreatePutMethodOptions<TOptions>['extraChecks'];\n  getToken?: CreatePutMethodOptions<TOptions>['getToken'];\n}): Promise<TOptions> {\n  if (!pathname) {\n    throw new BlobError('pathname is required');\n  }\n\n  if (pathname.length > MAXIMUM_PATHNAME_LENGTH) {\n    throw new BlobError(\n      `pathname is too long, maximum length is ${MAXIMUM_PATHNAME_LENGTH}`,\n    );\n  }\n\n  if (!options) {\n    throw new BlobError('missing options, see usage');\n  }\n\n  // eslint-disable-next-line @typescript-eslint/no-unnecessary-condition -- Runtime check for DX.\n  if (options.access !== 'public') {\n    throw new BlobError('access must be \"public\"');\n  }\n\n  if (extraChecks) {\n    extraChecks(options);\n  }\n\n  if (getToken) {\n    options.token = await getToken(pathname, options);\n  }\n\n  return options;\n}\n","import { BlobServiceNotAvailable, requestApi } from '../api';\nimport { debug } from '../debug';\nimport type { CommonCreateBlobOptions, BlobCommandOptions } from '../helpers';\nimport type {\n  CreatePutMethodOptions,\n  PutBlobApiResponse,\n  PutBlobResult,\n} from '../put-helpers';\nimport { createPutHeaders, createPutOptions } from '../put-helpers';\nimport type { Part } from './helpers';\n\n// shared interface for server and client\nexport interface CommonCompleteMultipartUploadOptions {\n  uploadId: string;\n  key: string;\n}\n\nexport type CompleteMultipartUploadCommandOptions =\n  CommonCompleteMultipartUploadOptions & CommonCreateBlobOptions;\n\nexport function createCompleteMultipartUploadMethod<\n  TOptions extends CompleteMultipartUploadCommandOptions,\n>({ allowedOptions, getToken, extraChecks }: CreatePutMethodOptions<TOptions>) {\n  return async (pathname: string, parts: Part[], optionsInput: TOptions) => {\n    const options = await createPutOptions({\n      pathname,\n      options: optionsInput,\n      extraChecks,\n      getToken,\n    });\n\n    const headers = createPutHeaders(allowedOptions, options);\n\n    return completeMultipartUpload({\n      uploadId: options.uploadId,\n      key: options.key,\n      pathname,\n      headers,\n      options,\n      parts,\n    });\n  };\n}\n\nexport async function completeMultipartUpload({\n  uploadId,\n  key,\n  pathname,\n  parts,\n  headers,\n  options,\n}: {\n  uploadId: string;\n  key: string;\n  pathname: string;\n  parts: Part[];\n  headers: Record<string, string>;\n  options: BlobCommandOptions;\n}): Promise<PutBlobResult> {\n  try {\n    const response = await requestApi<PutBlobApiResponse>(\n      `/mpu/${pathname}`,\n      {\n        method: 'POST',\n        headers: {\n          ...headers,\n          'content-type': 'application/json',\n          'x-mpu-action': 'complete',\n          'x-mpu-upload-id': uploadId,\n          // key can be any utf8 character so we need to encode it as HTTP headers can only be us-ascii\n          // https://www.rfc-editor.org/rfc/rfc7230#swection-3.2.4\n          'x-mpu-key': encodeURI(key),\n        },\n        body: JSON.stringify(parts),\n        signal: options.abortSignal,\n      },\n      options,\n    );\n\n    debug('mpu: complete', response);\n\n    return response;\n  } catch (error: unknown) {\n    if (\n      error instanceof TypeError &&\n      (error.message === 'Failed to fetch' || error.message === 'fetch failed')\n    ) {\n      throw new BlobServiceNotAvailable();\n    } else {\n      throw error;\n    }\n  }\n}\n","import { BlobServiceNotAvailable, requestApi } from '../api';\nimport { debug } from '../debug';\nimport type { BlobCommandOptions, CommonCreateBlobOptions } from '../helpers';\nimport type { CreatePutMethodOptions } from '../put-helpers';\nimport { createPutHeaders, createPutOptions } from '../put-helpers';\n\nexport function createCreateMultipartUploadMethod<\n  TOptions extends CommonCreateBlobOptions,\n>({ allowedOptions, getToken, extraChecks }: CreatePutMethodOptions<TOptions>) {\n  return async (pathname: string, optionsInput: TOptions) => {\n    const options = await createPutOptions({\n      pathname,\n      options: optionsInput,\n      extraChecks,\n      getToken,\n    });\n\n    const headers = createPutHeaders(allowedOptions, options);\n\n    const createMultipartUploadResponse = await createMultipartUpload(\n      pathname,\n      headers,\n      options,\n    );\n\n    return {\n      key: createMultipartUploadResponse.key,\n      uploadId: createMultipartUploadResponse.uploadId,\n    };\n  };\n}\n\ninterface CreateMultipartUploadApiResponse {\n  uploadId: string;\n  key: string;\n}\n\nexport async function createMultipartUpload(\n  pathname: string,\n  headers: Record<string, string>,\n  options: BlobCommandOptions,\n): Promise<CreateMultipartUploadApiResponse> {\n  debug('mpu: create', 'pathname:', pathname);\n\n  try {\n    const response = await requestApi<CreateMultipartUploadApiResponse>(\n      `/mpu/${pathname}`,\n      {\n        method: 'POST',\n        headers: {\n          ...headers,\n          'x-mpu-action': 'create',\n        },\n        signal: options.abortSignal,\n      },\n      options,\n    );\n\n    debug('mpu: create', response);\n\n    return response;\n  } catch (error: unknown) {\n    if (\n      error instanceof TypeError &&\n      (error.message === 'Failed to fetch' || error.message === 'fetch failed')\n    ) {\n      throw new BlobServiceNotAvailable();\n    } else {\n      throw error;\n    }\n  }\n}\n","import bytes from 'bytes';\nimport type { BodyInit } from 'undici';\nimport { BlobServiceNotAvailable, requestApi } from '../api';\nimport { debug } from '../debug';\nimport {\n  type CommonCreateBlobOptions,\n  type BlobCommandOptions,\n  BlobError,\n  isPlainObject,\n} from '../helpers';\nimport { createPutHeaders, createPutOptions } from '../put-helpers';\nimport type { PutBody, CreatePutMethodOptions } from '../put-helpers';\nimport type { Part, PartInput } from './helpers';\n\n// shared interface for server and client\nexport interface CommonMultipartUploadOptions {\n  uploadId: string;\n  key: string;\n  partNumber: number;\n}\n\nexport type UploadPartCommandOptions = CommonMultipartUploadOptions &\n  CommonCreateBlobOptions;\n\nexport function createUploadPartMethod<\n  TOptions extends UploadPartCommandOptions,\n>({ allowedOptions, getToken, extraChecks }: CreatePutMethodOptions<TOptions>) {\n  return async (\n    pathname: string,\n    body: PutBody,\n    optionsInput: TOptions,\n  ): Promise<Part> => {\n    const options = await createPutOptions({\n      pathname,\n      options: optionsInput,\n      extraChecks,\n      getToken,\n    });\n\n    const headers = createPutHeaders(allowedOptions, options);\n\n    if (isPlainObject(body)) {\n      throw new BlobError(\n        \"Body must be a string, buffer or stream. You sent a plain JavaScript object, double check what you're trying to upload.\",\n      );\n    }\n\n    const result = await uploadPart({\n      uploadId: options.uploadId,\n      key: options.key,\n      pathname,\n      part: { blob: body, partNumber: options.partNumber },\n      headers,\n      options,\n    });\n\n    return {\n      etag: result.etag,\n      partNumber: options.partNumber,\n    };\n  };\n}\n\nexport async function uploadPart({\n  uploadId,\n  key,\n  pathname,\n  headers,\n  options,\n  internalAbortController = new AbortController(),\n  part,\n}: {\n  uploadId: string;\n  key: string;\n  pathname: string;\n  headers: Record<string, string>;\n  options: BlobCommandOptions;\n  internalAbortController?: AbortController;\n  part: PartInput;\n}): Promise<UploadPartApiResponse> {\n  const responsePromise = requestApi<UploadPartApiResponse>(\n    `/mpu/${pathname}`,\n    {\n      signal: internalAbortController.signal,\n      method: 'POST',\n      headers: {\n        ...headers,\n        'x-mpu-action': 'upload',\n        'x-mpu-key': encodeURI(key),\n        'x-mpu-upload-id': uploadId,\n        'x-mpu-part-number': part.partNumber.toString(),\n      },\n      // weird things between undici types and native fetch types\n      body: part.blob as BodyInit,\n      // required in order to stream some body types to Cloudflare\n      // currently only supported in Node.js, we may have to feature detect this\n      // note: this doesn't send a content-length to the server\n      duplex: 'half',\n    },\n    options,\n  );\n\n  function handleAbort(): void {\n    internalAbortController.abort();\n  }\n\n  if (options.abortSignal?.aborted) {\n    // abort if the signal is already aborted\n    handleAbort();\n  } else {\n    // we connect the internal abort controller to the external abortSignal to allow the user to cancel the upload\n    options.abortSignal?.addEventListener('abort', handleAbort);\n  }\n\n  const response = await responsePromise;\n\n  options.abortSignal?.removeEventListener('abort', handleAbort);\n\n  return response;\n}\n\n// Most browsers will cap requests at 6 concurrent uploads per domain (Vercel Blob API domain)\n// In other environments, we can afford to be more aggressive\nconst maxConcurrentUploads = typeof window !== 'undefined' ? 6 : 8;\n\n// 5MB is the minimum part size accepted by Vercel Blob, but we set our default part size to 8mb like the aws cli\nconst partSizeInBytes = 8 * 1024 * 1024;\n\nconst maxBytesInMemory = maxConcurrentUploads * partSizeInBytes * 2;\n\ninterface UploadPartApiResponse {\n  etag: string;\n}\n\nexport interface BlobUploadPart {\n  partNumber: number;\n  blob: Blob;\n}\n\n// Can we rewrite this function without new Promise?\nexport function uploadAllParts({\n  uploadId,\n  key,\n  pathname,\n  stream,\n  headers,\n  options,\n}: {\n  uploadId: string;\n  key: string;\n  pathname: string;\n  stream: ReadableStream<ArrayBuffer>;\n  headers: Record<string, string>;\n  options: BlobCommandOptions;\n}): Promise<Part[]> {\n  debug('mpu: upload init', 'key:', key);\n  const internalAbortController = new AbortController();\n\n  return new Promise((resolve, reject) => {\n    const partsToUpload: BlobUploadPart[] = [];\n    const completedParts: Part[] = [];\n    const reader = stream.getReader();\n    let activeUploads = 0;\n    let reading = false;\n    let currentPartNumber = 1;\n    // this next variable is used to escape the read loop when an error occurs\n    let rejected = false;\n    let currentBytesInMemory = 0;\n    let doneReading = false;\n    let bytesSent = 0;\n\n    // This must be outside the read loop, in case we reach the maxBytesInMemory and\n    // we exit the loop but some bytes are still to be sent on the next read invocation.\n    let arrayBuffers: ArrayBuffer[] = [];\n    let currentPartBytesRead = 0;\n\n    read().catch(cancel);\n\n    async function read(): Promise<void> {\n      debug(\n        'mpu: upload read start',\n        'activeUploads:',\n        activeUploads,\n        'currentBytesInMemory:',\n        `${bytes(currentBytesInMemory)}/${bytes(maxBytesInMemory)}`,\n        'bytesSent:',\n        bytes(bytesSent),\n      );\n\n      reading = true;\n\n      while (currentBytesInMemory < maxBytesInMemory && !rejected) {\n        try {\n          // eslint-disable-next-line no-await-in-loop -- A for loop is fine here.\n          const { value, done } = await reader.read();\n\n          if (done) {\n            doneReading = true;\n            debug('mpu: upload read consumed the whole stream');\n            // done is sent when the stream is fully consumed. That's why we're not using the value here.\n            if (arrayBuffers.length > 0) {\n              partsToUpload.push({\n                partNumber: currentPartNumber++,\n                blob: new Blob(arrayBuffers, {\n                  type: 'application/octet-stream',\n                }),\n              });\n\n              sendParts();\n            }\n            reading = false;\n            return;\n          }\n\n          currentBytesInMemory += value.byteLength;\n\n          // This code ensures that each part will be exactly of `partSizeInBytes` size\n          // Otherwise R2 will refuse it. AWS S3 is fine with parts of different sizes.\n          let valueOffset = 0;\n          while (valueOffset < value.byteLength) {\n            const remainingPartSize = partSizeInBytes - currentPartBytesRead;\n            const endOffset = Math.min(\n              valueOffset + remainingPartSize,\n              value.byteLength,\n            );\n\n            const chunk = value.slice(valueOffset, endOffset);\n\n            arrayBuffers.push(chunk);\n            currentPartBytesRead += chunk.byteLength;\n            valueOffset = endOffset;\n\n            if (currentPartBytesRead === partSizeInBytes) {\n              partsToUpload.push({\n                partNumber: currentPartNumber++,\n                blob: new Blob(arrayBuffers, {\n                  type: 'application/octet-stream',\n                }),\n              });\n\n              arrayBuffers = [];\n              currentPartBytesRead = 0;\n              sendParts();\n            }\n          }\n        } catch (error) {\n          cancel(error);\n        }\n      }\n\n      debug(\n        'mpu: upload read end',\n        'activeUploads:',\n        activeUploads,\n        'currentBytesInMemory:',\n        `${bytes(currentBytesInMemory)}/${bytes(maxBytesInMemory)}`,\n        'bytesSent:',\n        bytes(bytesSent),\n      );\n\n      reading = false;\n    }\n\n    async function sendPart(part: BlobUploadPart): Promise<void> {\n      activeUploads++;\n\n      debug(\n        'mpu: upload send part start',\n        'partNumber:',\n        part.partNumber,\n        'size:',\n        part.blob.size,\n        'activeUploads:',\n        activeUploads,\n        'currentBytesInMemory:',\n        `${bytes(currentBytesInMemory)}/${bytes(maxBytesInMemory)}`,\n        'bytesSent:',\n        bytes(bytesSent),\n      );\n\n      try {\n        const completedPart = await uploadPart({\n          uploadId,\n          key,\n          pathname,\n          headers,\n          options,\n          internalAbortController,\n          part,\n        });\n\n        debug(\n          'mpu: upload send part end',\n          'partNumber:',\n          part.partNumber,\n          'activeUploads',\n          activeUploads,\n          'currentBytesInMemory:',\n          `${bytes(currentBytesInMemory)}/${bytes(maxBytesInMemory)}`,\n          'bytesSent:',\n          bytes(bytesSent),\n        );\n\n        if (rejected) {\n          return;\n        }\n\n        completedParts.push({\n          partNumber: part.partNumber,\n          etag: completedPart.etag,\n        });\n\n        currentBytesInMemory -= part.blob.size;\n        activeUploads--;\n        bytesSent += part.blob.size;\n\n        if (partsToUpload.length > 0) {\n          sendParts();\n        }\n\n        if (doneReading) {\n          if (activeUploads === 0) {\n            reader.releaseLock();\n            resolve(completedParts);\n          }\n          return;\n        }\n\n        if (!reading) {\n          read().catch(cancel);\n        }\n      } catch (error) {\n        // cancel if fetch throws an error\n        cancel(error);\n      }\n    }\n\n    function sendParts(): void {\n      if (rejected) {\n        return;\n      }\n\n      debug(\n        'send parts',\n        'activeUploads',\n        activeUploads,\n        'partsToUpload',\n        partsToUpload.length,\n      );\n\n      while (activeUploads < maxConcurrentUploads && partsToUpload.length > 0) {\n        const partToSend = partsToUpload.shift();\n        if (partToSend) {\n          void sendPart(partToSend);\n        }\n      }\n    }\n\n    function cancel(error: unknown): void {\n      // a previous call already rejected the whole call, ignore\n      if (rejected) {\n        return;\n      }\n      rejected = true;\n      internalAbortController.abort();\n      reader.releaseLock();\n      if (\n        error instanceof TypeError &&\n        (error.message === 'Failed to fetch' ||\n          error.message === 'fetch failed')\n      ) {\n        reject(new BlobServiceNotAvailable());\n      } else {\n        reject(error as Error);\n      }\n    }\n  });\n}\n","// eslint-disable-next-line unicorn/prefer-node-protocol -- node:stream does not resolve correctly in browser and edge\nimport { Readable } from 'stream';\n// eslint-disable-next-line unicorn/prefer-node-protocol -- node:buffer does not resolve correctly in browser and edge\nimport type { Buffer } from 'buffer';\nimport isBuffer from 'is-buffer';\nimport type { PutBody } from '../put-helpers';\n\nexport interface PartInput {\n  partNumber: number;\n  blob: PutBody;\n}\n\nexport interface Part {\n  partNumber: number;\n  etag: string;\n}\n\nexport function toReadableStream(value: PutBody): ReadableStream<ArrayBuffer> {\n  // Already a ReadableStream, nothing to do\n  if (value instanceof ReadableStream) {\n    return value as ReadableStream<ArrayBuffer>;\n  }\n\n  // In the case of a Blob or File (which inherits from Blob), we could use .slice() to create pointers\n  // to the original data instead of loading data in memory gradually.\n  // Here's an explanation on this subject: https://stackoverflow.com/a/24834417\n  if (value instanceof Blob) {\n    return value.stream();\n  }\n\n  if (isNodeJsReadableStream(value)) {\n    return Readable.toWeb(value) as ReadableStream<ArrayBuffer>;\n  }\n\n  let streamValue: Uint8Array | ArrayBuffer;\n\n  if (value instanceof ArrayBuffer) {\n    streamValue = value;\n  } else if (isNodeJsBufferOrString(value)) {\n    streamValue = value.buffer;\n  } else {\n    streamValue = stringToUint8Array(value);\n  }\n\n  // from https://github.com/sindresorhus/to-readable-stream/blob/main/index.js\n  return new ReadableStream<ArrayBuffer>({\n    start(controller) {\n      controller.enqueue(streamValue);\n      controller.close();\n    },\n  });\n}\n\n// From https://github.com/sindresorhus/is-stream/\nfunction isNodeJsReadableStream(value: PutBody): value is Readable {\n  return (\n    typeof value === 'object' &&\n    typeof (value as Readable).pipe === 'function' &&\n    (value as Readable).readable &&\n    typeof (value as Readable)._read === 'function' &&\n    // @ts-expect-error _readableState does exists on Readable\n    typeof value._readableState === 'object'\n  );\n}\n\nfunction stringToUint8Array(s: string): Uint8Array {\n  const enc = new TextEncoder();\n  return enc.encode(s);\n}\n\nfunction isNodeJsBufferOrString(input: Buffer | string): input is Buffer {\n  return isBuffer(input);\n}\n","import { debug } from '../debug';\nimport type { BlobCommandOptions } from '../helpers';\nimport type { PutBody, PutBlobResult } from '../put-helpers';\nimport { completeMultipartUpload } from './complete';\nimport { createMultipartUpload } from './create';\nimport { toReadableStream } from './helpers';\nimport { uploadAllParts } from './upload';\n\n// this automatically slices the body into parts and uploads all of them as multiple parts\nexport async function uncontrolledMultipartUpload(\n  pathname: string,\n  body: PutBody,\n  headers: Record<string, string>,\n  options: BlobCommandOptions,\n): Promise<PutBlobResult> {\n  debug('mpu: init', 'pathname:', pathname, 'headers:', headers);\n\n  const stream = toReadableStream(body);\n\n  // Step 1: Start multipart upload\n  const createMultipartUploadResponse = await createMultipartUpload(\n    pathname,\n    headers,\n    options,\n  );\n\n  // Step 2: Upload parts one by one\n  const parts = await uploadAllParts({\n    uploadId: createMultipartUploadResponse.uploadId,\n    key: createMultipartUploadResponse.key,\n    pathname,\n    stream,\n    headers,\n    options,\n  });\n\n  // Step 3: Complete multipart upload\n  const blob = await completeMultipartUpload({\n    uploadId: createMultipartUploadResponse.uploadId,\n    key: createMultipartUploadResponse.key,\n    pathname,\n    parts,\n    headers,\n    options,\n  });\n\n  return blob;\n}\n","import type { BodyInit } from 'undici';\nimport { requestApi } from './api';\nimport type { CommonCreateBlobOptions } from './helpers';\nimport { BlobError, isPlainObject } from './helpers';\nimport { uncontrolledMultipartUpload } from './multipart/uncontrolled';\nimport type {\n  CreatePutMethodOptions,\n  PutBody,\n  PutBlobApiResponse,\n  PutBlobResult,\n} from './put-helpers';\nimport { createPutOptions, createPutHeaders } from './put-helpers';\n\nexport interface PutCommandOptions extends CommonCreateBlobOptions {\n  /**\n   * Whether to use multipart upload. Use this when uploading large files. It will split the file into multiple parts, upload them in parallel and retry failed parts.\n   * @defaultvalue false\n   */\n  multipart?: boolean;\n}\n\nexport function createPutMethod<TOptions extends PutCommandOptions>({\n  allowedOptions,\n  getToken,\n  extraChecks,\n}: CreatePutMethodOptions<TOptions>) {\n  return async function put(\n    pathname: string,\n    body: PutBody,\n    optionsInput: TOptions,\n  ): Promise<PutBlobResult> {\n    if (!body) {\n      throw new BlobError('body is required');\n    }\n\n    if (isPlainObject(body)) {\n      throw new BlobError(\n        \"Body must be a string, buffer or stream. You sent a plain JavaScript object, double check what you're trying to upload.\",\n      );\n    }\n\n    const options = await createPutOptions({\n      pathname,\n      options: optionsInput,\n      extraChecks,\n      getToken,\n    });\n\n    const headers = createPutHeaders(allowedOptions, options);\n\n    if (options.multipart === true) {\n      return uncontrolledMultipartUpload(pathname, body, headers, options);\n    }\n\n    const response = await requestApi<PutBlobApiResponse>(\n      `/${pathname}`,\n      {\n        method: 'PUT',\n        body: body as BodyInit,\n        headers,\n        // required in order to stream some body types to Cloudflare\n        // currently only supported in Node.js, we may have to feature detect this\n        // note: this doesn't send a content-length to the server\n        duplex: 'half',\n        signal: options.abortSignal,\n      },\n      options,\n    );\n\n    return {\n      url: response.url,\n      downloadUrl: response.downloadUrl,\n      pathname: response.pathname,\n      contentType: response.contentType,\n      contentDisposition: response.contentDisposition,\n    };\n  };\n}\n","import {\n  BlobError,\n  isPlainObject,\n  type CommonCreateBlobOptions,\n} from '../helpers';\nimport type { CreatePutMethodOptions, PutBody } from '../put-helpers';\nimport { createPutHeaders, createPutOptions } from '../put-helpers';\nimport { completeMultipartUpload } from './complete';\nimport { createMultipartUpload } from './create';\nimport type { Part } from './helpers';\nimport { uploadPart as rawUploadPart } from './upload';\n\nexport function createCreateMultipartUploaderMethod<\n  TOptions extends CommonCreateBlobOptions,\n>({ allowedOptions, getToken, extraChecks }: CreatePutMethodOptions<TOptions>) {\n  return async (pathname: string, optionsInput: TOptions) => {\n    const options = await createPutOptions({\n      pathname,\n      options: optionsInput,\n      extraChecks,\n      getToken,\n    });\n\n    const headers = createPutHeaders(allowedOptions, options);\n\n    const createMultipartUploadResponse = await createMultipartUpload(\n      pathname,\n      headers,\n      options,\n    );\n\n    return {\n      key: createMultipartUploadResponse.key,\n      uploadId: createMultipartUploadResponse.uploadId,\n\n      async uploadPart(partNumber: number, body: PutBody) {\n        if (isPlainObject(body)) {\n          throw new BlobError(\n            \"Body must be a string, buffer or stream. You sent a plain JavaScript object, double check what you're trying to upload.\",\n          );\n        }\n\n        const result = await rawUploadPart({\n          uploadId: createMultipartUploadResponse.uploadId,\n          key: createMultipartUploadResponse.key,\n          pathname,\n          part: { partNumber, blob: body },\n          headers,\n          options,\n        });\n\n        return {\n          etag: result.etag,\n          partNumber,\n        };\n      },\n\n      async complete(parts: Part[]) {\n        return completeMultipartUpload({\n          uploadId: createMultipartUploadResponse.uploadId,\n          key: createMultipartUploadResponse.key,\n          pathname,\n          parts,\n          headers,\n          options,\n        });\n      },\n    };\n  };\n}\n","import { requestApi } from './api';\nimport type { BlobCommandOptions } from './helpers';\nimport { putOptionHeaderMap, type PutBlobApiResponse } from './put-helpers';\n\nexport interface CreateFolderResult {\n  pathname: string;\n  url: string;\n}\n\n/**\n * Creates a folder in your store. Vercel Blob has no real concept of folders, our file browser on Vercel.com displays folders based on the presence of trailing slashes in the pathname. Unless you are building a file browser system, you probably don't need to use this method.\n *\n * Use the resulting `url` to delete the folder, just like you would delete a blob.\n * @param pathname - Can be user1/ or user1/avatars/\n * @param options - Additional options like `token`\n */\nexport async function createFolder(\n  pathname: string,\n  options: BlobCommandOptions = {},\n): Promise<CreateFolderResult> {\n  const path = pathname.endsWith('/') ? pathname : `${pathname}/`;\n\n  const headers: Record<string, string> = {};\n\n  headers[putOptionHeaderMap.addRandomSuffix] = '0';\n\n  const response = await requestApi<PutBlobApiResponse>(\n    `/${path}`,\n    {\n      method: 'PUT',\n      headers,\n      signal: options.abortSignal,\n    },\n    options,\n  );\n\n  return {\n    url: response.url,\n    pathname: response.pathname,\n  };\n}\n"]}